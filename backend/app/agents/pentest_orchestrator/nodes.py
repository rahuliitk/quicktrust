"""Node functions for the pentest orchestrator LangGraph."""
import json
from datetime import datetime, timezone

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.agents.common.llm import call_llm_json
from app.agents.pentest_orchestrator.prompts import (
    SYSTEM_PROMPT,
    GENERATE_TEST_PLAN_PROMPT,
    SIMULATE_FINDINGS_PROMPT,
)
from app.agents.pentest_orchestrator.state import PentestOrchestratorState
from app.models.agent_run import AgentRun
from app.models.control import Control
from app.models.organization import Organization


async def load_org_context(
    state: PentestOrchestratorState, db: AsyncSession
) -> dict:
    """Load organization tech stack, cloud providers, and controls from DB."""
    org_id = state["org_id"]

    # Load organization
    result = await db.execute(
        select(Organization).where(Organization.id == org_id)
    )
    org = result.scalar_one_or_none()
    if not org:
        return {"error": f"Organization {org_id} not found"}

    # Load controls for summary
    controls_result = await db.execute(
        select(Control).where(Control.org_id == org_id)
    )
    controls = controls_result.scalars().all()

    # Build controls summary
    status_counts = {}
    security_controls = []
    for c in controls:
        status_counts[c.status] = status_counts.get(c.status, 0) + 1
        if any(kw in (c.title or "").lower() for kw in [
            "access", "auth", "encrypt", "firewall", "monitor",
            "logging", "backup", "patch", "vulnerability", "network",
        ]):
            security_controls.append(c.title)

    cloud_providers = org.cloud_providers if isinstance(org.cloud_providers, list) else (
        org.cloud_providers.get("providers", []) if isinstance(org.cloud_providers, dict) else []
    )
    tech_stack = org.tech_stack if isinstance(org.tech_stack, list) else (
        org.tech_stack.get("technologies", []) if isinstance(org.tech_stack, dict) else []
    )

    org_context = {
        "name": org.name,
        "industry": org.industry or "Technology",
        "company_size": org.company_size or "50-200",
        "cloud_providers": cloud_providers,
        "tech_stack": tech_stack,
        "total_controls": len(controls),
        "control_status_breakdown": status_counts,
        "security_controls": security_controls[:20],
    }

    return {"org_context": org_context}


async def generate_test_plan(
    state: PentestOrchestratorState, db: AsyncSession
) -> dict:
    """Use LLM to create a structured pentest plan based on OWASP and tech stack."""
    ctx = state["org_context"]

    controls_summary = json.dumps({
        "total": ctx["total_controls"],
        "by_status": ctx["control_status_breakdown"],
        "security_controls": ctx["security_controls"][:10],
    })

    prompt = GENERATE_TEST_PLAN_PROMPT.format(
        industry=ctx["industry"],
        company_size=ctx["company_size"],
        cloud_providers=", ".join(ctx["cloud_providers"]) or "Not specified",
        tech_stack=", ".join(ctx["tech_stack"]) or "Not specified",
        total_controls=ctx["total_controls"],
        controls_summary=controls_summary,
    )

    try:
        result = await call_llm_json(
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            max_tokens=8192,
        )
        test_plan = result.get("test_plan", result)
        return {"test_plan": test_plan}
    except Exception as e:
        # Fallback: generate a basic test plan
        fallback_plan = {
            "scope": {
                "in_scope": ["Web applications", "API endpoints", "Cloud infrastructure", "Authentication systems"],
                "out_of_scope": ["Physical security", "Social engineering", "Third-party vendor systems"],
            },
            "methodology": "OWASP Testing Guide v4.2 + PTES",
            "categories": [
                {
                    "name": "Web Application Testing",
                    "description": "Testing web applications against OWASP Top 10",
                    "test_cases": [
                        {"id": "WEB-001", "title": "SQL Injection Testing", "description": "Test input fields for SQL injection vulnerabilities", "severity_if_found": "critical", "owasp_category": "A03:2021-Injection"},
                        {"id": "WEB-002", "title": "XSS Testing", "description": "Test for reflected and stored cross-site scripting", "severity_if_found": "high", "owasp_category": "A03:2021-Injection"},
                        {"id": "WEB-003", "title": "Authentication Bypass", "description": "Test authentication mechanisms for bypass vulnerabilities", "severity_if_found": "critical", "owasp_category": "A07:2021-Identification and Authentication Failures"},
                    ],
                },
                {
                    "name": "API Security Testing",
                    "description": "Testing API endpoints for security vulnerabilities",
                    "test_cases": [
                        {"id": "API-001", "title": "Broken Object Level Authorization", "description": "Test for IDOR vulnerabilities in API endpoints", "severity_if_found": "high", "owasp_category": "A01:2023-BOLA"},
                        {"id": "API-002", "title": "Rate Limiting", "description": "Test API rate limiting and throttling", "severity_if_found": "medium", "owasp_category": "A04:2023-Unrestricted Resource Consumption"},
                    ],
                },
                {
                    "name": "Cloud Infrastructure Testing",
                    "description": "Testing cloud configuration and security controls",
                    "test_cases": [
                        {"id": "CLD-001", "title": "Storage Bucket Permissions", "description": "Check for publicly accessible storage buckets", "severity_if_found": "critical", "owasp_category": "A01:2021-Broken Access Control"},
                        {"id": "CLD-002", "title": "IAM Policy Review", "description": "Review IAM policies for over-permissive access", "severity_if_found": "high", "owasp_category": "A01:2021-Broken Access Control"},
                    ],
                },
            ],
            "timeline_days": 10,
            "tools_referenced": ["Burp Suite", "OWASP ZAP", "Nmap", "Nuclei", "ScoutSuite"],
        }
        return {"test_plan": fallback_plan, "error": f"LLM fallback used: {str(e)}"}


async def simulate_findings(
    state: PentestOrchestratorState, db: AsyncSession
) -> dict:
    """Use LLM to generate realistic simulated findings based on org context."""
    ctx = state["org_context"]
    test_plan = state["test_plan"]

    controls_summary = json.dumps({
        "total": ctx["total_controls"],
        "by_status": ctx["control_status_breakdown"],
        "security_controls": ctx["security_controls"][:10],
    })

    prompt = SIMULATE_FINDINGS_PROMPT.format(
        industry=ctx["industry"],
        cloud_providers=", ".join(ctx["cloud_providers"]) or "Not specified",
        tech_stack=", ".join(ctx["tech_stack"]) or "Not specified",
        controls_summary=controls_summary,
        test_plan_json=json.dumps(test_plan, indent=2),
    )

    try:
        result = await call_llm_json(
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            max_tokens=8192,
        )
        findings = result.get("findings", [])
        return {"simulated_findings": findings}
    except Exception as e:
        # Fallback: generate basic simulated findings
        fallback_findings = [
            {
                "title": "Missing Security Headers",
                "description": "The web application is missing several important security headers including X-Content-Type-Options, X-Frame-Options, and Content-Security-Policy.",
                "severity": "medium",
                "cvss_score": 5.3,
                "affected_component": "Web Application HTTP Responses",
                "steps_to_reproduce": ["Send HTTP request to application root", "Examine response headers", "Note missing security headers"],
                "remediation": "Configure web server to include X-Content-Type-Options: nosniff, X-Frame-Options: DENY, and a restrictive Content-Security-Policy header.",
                "owasp_category": "A05:2021-Security Misconfiguration",
                "business_impact": "Increases susceptibility to clickjacking and MIME-type sniffing attacks.",
            },
            {
                "title": "Verbose Error Messages",
                "description": "The application returns detailed error messages including stack traces and internal paths when unexpected errors occur.",
                "severity": "low",
                "cvss_score": 3.7,
                "affected_component": "Application Error Handling",
                "steps_to_reproduce": ["Send malformed request to API endpoint", "Observe detailed error response with stack trace"],
                "remediation": "Implement custom error handling that returns generic error messages to users while logging detailed errors server-side.",
                "owasp_category": "A05:2021-Security Misconfiguration",
                "business_impact": "Information disclosure that could aid attackers in understanding the application architecture.",
            },
            {
                "title": "Insufficient Rate Limiting on Authentication Endpoint",
                "description": "The login endpoint does not implement adequate rate limiting, potentially allowing brute-force password attacks.",
                "severity": "high",
                "cvss_score": 7.5,
                "affected_component": "Authentication API",
                "steps_to_reproduce": ["Send multiple rapid login requests", "Observe no rate limiting or account lockout"],
                "remediation": "Implement rate limiting on authentication endpoints (e.g., max 5 attempts per minute) and account lockout after repeated failures.",
                "owasp_category": "A07:2021-Identification and Authentication Failures",
                "business_impact": "Could allow unauthorized access to user accounts through credential stuffing or brute-force attacks.",
            },
        ]
        return {"simulated_findings": fallback_findings, "error": f"LLM fallback used: {str(e)}"}


async def generate_report(
    state: PentestOrchestratorState, db: AsyncSession
) -> dict:
    """Format findings into a structured penetration test report."""
    ctx = state["org_context"]
    test_plan = state["test_plan"]
    findings = state["simulated_findings"]
    now = datetime.now(timezone.utc)

    # Calculate severity breakdown
    severity_counts = {}
    for f in findings:
        sev = f.get("severity", "medium")
        severity_counts[sev] = severity_counts.get(sev, 0) + 1

    # Calculate overall risk rating
    severity_weights = {"critical": 10, "high": 7, "medium": 4, "low": 2, "informational": 0}
    total_weight = sum(severity_weights.get(f.get("severity", "medium"), 4) for f in findings)
    avg_weight = total_weight / len(findings) if findings else 0

    if avg_weight >= 7:
        overall_rating = "critical"
    elif avg_weight >= 5:
        overall_rating = "high"
    elif avg_weight >= 3:
        overall_rating = "medium"
    else:
        overall_rating = "low"

    report = {
        "title": f"Penetration Test Report - {ctx['name']}",
        "generated_at": now.isoformat(),
        "type": "simulated",
        "disclaimer": "This report contains simulated findings based on organizational context analysis. It does NOT represent results from actual penetration testing.",
        "executive_summary": {
            "organization": ctx["name"],
            "scope": test_plan.get("scope", {}),
            "methodology": test_plan.get("methodology", "OWASP + PTES"),
            "total_findings": len(findings),
            "severity_breakdown": severity_counts,
            "overall_risk_rating": overall_rating,
            "timeline_days": test_plan.get("timeline_days", 10),
        },
        "findings": findings,
        "recommendations": [
            f"Address all {severity_counts.get('critical', 0)} critical findings immediately"
            if severity_counts.get("critical") else "No critical findings identified",
            f"Remediate {severity_counts.get('high', 0)} high-severity findings within 30 days"
            if severity_counts.get("high") else "No high-severity findings identified",
            "Conduct a follow-up assessment after remediation",
            "Implement continuous security monitoring",
        ],
        "tools_referenced": test_plan.get("tools_referenced", []),
    }

    return {"report_data": report}


async def save_results(
    state: PentestOrchestratorState, db: AsyncSession
) -> dict:
    """Save report data to agent_run output."""
    agent_run_id = state["agent_run_id"]
    report = state["report_data"]

    result = await db.execute(
        select(AgentRun).where(AgentRun.id == agent_run_id)
    )
    agent_run = result.scalar_one_or_none()
    if agent_run:
        agent_run.output_data = {
            "report": report,
            "findings_count": report["executive_summary"]["total_findings"],
            "overall_risk_rating": report["executive_summary"]["overall_risk_rating"],
        }

    await db.commit()

    return {"saved": True}
